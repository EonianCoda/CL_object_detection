{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T03:33:38.323738Z",
     "start_time": "2021-06-01T03:33:38.177971Z"
    }
   },
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T16:54:20.288210Z",
     "start_time": "2021-06-15T16:54:14.113272Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from retinanet import model\n",
    "from retinanet import coco_eval\n",
    "from retinanet.dataloader import CocoDataset_inOrder, collater, Resizer, AspectRatioBasedSampler, Augmenter, Normalizer\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import torch\n",
    "\n",
    "\n",
    "root_path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/'\n",
    "method = 'w_distillation'\n",
    "data_split = '15+1'\n",
    "start_round = 2\n",
    "batch_size = 2\n",
    "\n",
    "def get_checkpoint_path(method, now_round, epoch):\n",
    "    global root_path\n",
    "    global data_split\n",
    "    \n",
    "    path = os.path.join(root_path, 'model', method, 'round{}'.format(now_round), data_split,'voc_retinanet_{}_checkpoint.pt'.format(epoch))\n",
    "    return path\n",
    "\n",
    "def readCheckpoint(method, now_round, epoch, retinanet, optimizer = None, scheduler = None):\n",
    "    print('readcheckpoint at Round{} Epoch{}'.format(now_round, epoch))\n",
    "    prev_checkpoint = torch.load(get_checkpoint_path(method, now_round, epoch))\n",
    "    retinanet.load_state_dict(prev_checkpoint['model_state_dict'])\n",
    "    if optimizer != None:\n",
    "        optimizer.load_state_dict(prev_checkpoint['optimizer_state_dict'])\n",
    "    if scheduler != None:\n",
    "        scheduler.load_state_dict(prev_checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "\n",
    "coco_path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012'\n",
    "\n",
    "dataset_train = CocoDataset_inOrder(coco_path, set_name='TrainVoc2012', dataset = 'voc',\n",
    "                                    transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]), \n",
    "                                    start_round=start_round, data_split = data_split)\n",
    "\n",
    "sampler = AspectRatioBasedSampler(dataset_train, batch_size = batch_size, drop_last=False)\n",
    "dataloader_train = DataLoader(dataset_train, num_workers=2, collate_fn=collater, batch_sampler=sampler)\n",
    "\n",
    "retinanet = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "\n",
    "# optimizer = optim.Adam(retinanet.parameters(), lr=1e-5)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "# loss_hist = collections.deque(maxlen=500)\n",
    "\n",
    "# readCheckpoint(method, start_round, 30, retinanet)#, optimizer, scheduler)\n",
    "# retinanet = retinanet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T07:36:48.153006Z",
     "start_time": "2021-05-20T07:36:47.720911Z"
    }
   },
   "outputs": [],
   "source": [
    "c = torch.load(get_checkpoint_path('w_distillation', 2, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-20T07:36:59.327490Z",
     "start_time": "2021-05-20T07:36:59.321016Z"
    }
   },
   "outputs": [],
   "source": [
    "c['rehearsal_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T18:22:20.580507Z",
     "start_time": "2021-05-18T18:21:54.754484Z"
    }
   },
   "outputs": [],
   "source": [
    "for img in rehearsal_imgs:\n",
    "    im = cv2.imread(os.path.join(path, str(img)[:4] + '_' + str(img)[4:] +'.jpg'))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T07:34:10.340894Z",
     "start_time": "2021-05-10T07:34:10.072498Z"
    }
   },
   "outputs": [],
   "source": [
    "now_round = 1\n",
    "path = os.path.join(root_path, 'valResult', 'Voc', method)\n",
    "path = os.path.join(path, \"round{}\".format(now_round))\n",
    "result = json.load(open(os.path.join(path, '{}_bbox_results_{}_for{}epoch_1.json'.format(\"TestVoc2007\", now_round, 50))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T07:34:52.684821Z",
     "start_time": "2021-05-10T07:34:52.579410Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    thresold = 0.1 * i\n",
    "    new_result = []\n",
    "    print(thresold, len(result), end=' ')\n",
    "    for i,data in enumerate(result):\n",
    "        if data['score'] >= thresold:\n",
    "            new_result.append(data)\n",
    "    print(len(new_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:07:23.196776Z",
     "start_time": "2021-06-17T17:07:23.167523Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "def evaluate_coco(dataset, model, root_path, method, now_round, epoch, threshold=0.05):\n",
    "    \n",
    "    model.eval()\n",
    "    path = os.path.join(root_path, 'valResult', 'Voc', method)\n",
    "    path = os.path.join(path, \"round{}\".format(now_round))\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # start collecting results\n",
    "        results = []\n",
    "        image_ids = []\n",
    "\n",
    "#         for index in tqdm(range(len(dataset))):\n",
    "#             data = dataset[index]\n",
    "#             scale = data['scale']\n",
    "\n",
    "#             # run network\n",
    "#             if torch.cuda.is_available():\n",
    "#                 scores, labels, boxes = model(data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0))\n",
    "#             else:\n",
    "#                 scores, labels, boxes = model(data['img'].permute(2, 0, 1).float().unsqueeze(dim=0))\n",
    "#             scores = scores.cpu()\n",
    "#             labels = labels.cpu()\n",
    "#             boxes  = boxes.cpu()\n",
    "#             # correct boxes for image scale\n",
    "#             boxes /= scale\n",
    "\n",
    "#             if boxes.shape[0] > 0:\n",
    "#                 # change to (x, y, w, h) (MS COCO standard)\n",
    "#                 boxes[:, 2] -= boxes[:, 0]\n",
    "#                 boxes[:, 3] -= boxes[:, 1]\n",
    "\n",
    "#                 # compute predicted labels and scores\n",
    "#                 #for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "#                 for box_id in range(boxes.shape[0]):\n",
    "#                     score = float(scores[box_id])\n",
    "#                     label = int(labels[box_id])\n",
    "#                     box = boxes[box_id, :]\n",
    "\n",
    "#                     # scores are sorted, so we can break\n",
    "#                     if score < threshold:\n",
    "#                         break\n",
    "\n",
    "#                     # append detection for each positively labeled class\n",
    "#                     image_result = {\n",
    "#                         'image_id'    : dataset.image_ids[index],\n",
    "#                         'category_id' : dataset.label_to_coco_label(label),\n",
    "#                         'score'       : float(score),\n",
    "#                         'bbox'        : box.tolist(),\n",
    "#                     }\n",
    "\n",
    "#                     # append detection to results\n",
    "#                     results.append(image_result)\n",
    "\n",
    "#             # append image to list of processed images\n",
    "#             image_ids.append(dataset.image_ids[index])\n",
    "\n",
    "#         if not len(results):\n",
    "#             return\n",
    "\n",
    "#         # write output\n",
    "        \n",
    "#         path = os.path.join(root_path, 'valResult', 'Voc', method)\n",
    "#         checkDir(path)\n",
    "#         path = os.path.join(path, \"round{}\".format(now_round))\n",
    "#         checkDir(path)\n",
    "      \n",
    "#         json.dump(results, open(os.path.join(path , '{}_bbox_results_{}_for{}epoch.json'.format(dataset.set_name, now_round, epoch)), 'w') ,indent=4)\n",
    "        \n",
    "        image_ids = dataset.image_ids\n",
    "        # load results in COCO evaluation tool\n",
    "        coco_true = dataset.coco\n",
    "        \n",
    "        \n",
    "        result = json.load(open(os.path.join(path, '{}_bbox_results_{}_for{}epoch.json'.format(dataset.set_name, now_round, epoch))))\n",
    "        \n",
    "        new_result = []\n",
    "        print(threshold, len(result), end=' ')\n",
    "        for i,data in enumerate(result):\n",
    "            if data['score'] >= threshold:\n",
    "                new_result.append(data)\n",
    "        print(len(new_result))\n",
    "        \n",
    "    \n",
    "        coco_pred = coco_true.loadRes(new_result)\n",
    "        \n",
    "        return (coco_true, coco_pred)\n",
    "        #coco_pred = coco_true.loadRes(os.path.join(path, '{}_bbox_results_{}_for{}epoch_1.json'.format(dataset.set_name, now_round, epoch)))\n",
    "        #return (coco_true, coco_pred)\n",
    "        # run COCO evaluation\n",
    "        coco_eval = COCOeval(coco_true, coco_pred, 'bbox')\n",
    "        coco_eval.params.imgIds = image_ids\n",
    "        \n",
    "        precision_result = defaultdict()\n",
    "        recall_result = defaultdict()\n",
    "        \n",
    "        for class_id in dataset.seen_class_id:\n",
    "            class_name = dataset.cocoHelper.catIdToName(class_id)[0]\n",
    "            print('Evaluate {}:'.format(class_name))\n",
    "            coco_eval.params.catIds = [class_id]\n",
    "\n",
    "#             coco_eval.params.imgIds = list(set(dataset.cocoHelper.getImgIdFromCats(dataset.seen_class_id)) -  set(dataset.cocoHelper.getImgIdFromCats([2,4,8])))\n",
    "#             print(len(coco_eval.params.imgIds))\n",
    "#             coco_eval.params.imgIds = dataset.cocoHelper.getImgIdFromCats(class_id)\n",
    "            coco_eval.evaluate()\n",
    "            #return coco_eval\n",
    "#             for key in coco_eval.ious.keys():\n",
    "#                 print(coco_eval.ious[key])\n",
    "#                 break\n",
    "\n",
    "            coco_eval.accumulate()\n",
    "            coco_eval.summarize()\n",
    "            precision_result[class_name] = coco_eval.stats[1]\n",
    "            recall_result[class_name] = coco_eval.stats[8]\n",
    "\n",
    "        if len(dataset.seen_class_id) > 1:\n",
    "            print(\"Precision:\")\n",
    "            for name, ap in sorted(precision_result.items()):\n",
    "                print('{:<12} = {:0.2f}'.format(name, ap))\n",
    "\n",
    "            print(\"Recall:\")\n",
    "            for name, ap in sorted(recall_result.items()):\n",
    "                print('{:<12} = {:0.2f}'.format(name, ap))\n",
    "            \n",
    "            print(\"------------------------------------------\")\n",
    "            print('{:<12} = {:0.2f}'.format('MAP', np.mean([v for v in precision_result.values()])))\n",
    "            print('{:<12} = {:0.2f}'.format('Average Recall', np.mean([v for v in recall_result.values()])))\n",
    "            print(\"Precision:\")\n",
    "            for name, ap in sorted(precision_result.items()):\n",
    "                print('{:0.2f}'.format(ap))\n",
    "            print(\"Recall:\")\n",
    "            for name, ap in sorted(recall_result.items()):\n",
    "                print('{:0.2f}'.format(ap))\n",
    "        model.train()\n",
    "        \n",
    "        return\n",
    "def validation(val_model, dataType, model_round, model_epoch, val_round, years=2012,test_flag=False,custom_ids=[], threshold = 0.05):\n",
    "    global data_split\n",
    "    print(\"-\"*100)\n",
    "    print('Start eval on Round{} Epoch{}!'.format(model_round, model_epoch))\n",
    "\n",
    "    \n",
    "    val_model.eval()\n",
    "    val_model.freeze_bn()\n",
    "    set_name = \"{}Voc{}\".format(dataType, years)\n",
    "\n",
    "    print('Validation data is {} at Round{}'.format(set_name, val_round))\n",
    "    dataset_val = CocoDataset_inOrder(os.path.join(root_path, 'DataSet', 'VOC{}'.format(years)), set_name=set_name, dataset = 'voc', \n",
    "                    transform=transforms.Compose([Normalizer(), Resizer()]), \n",
    "                    start_round=val_round, data_split = data_split)\n",
    "#                     test_flag=test_flag,\n",
    "#                     custom_ids=custom_ids)\n",
    " \n",
    "    return evaluate_coco(dataset_val, val_model, root_path, method, model_round, model_epoch, threshold)\n",
    "    del dataset_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T12:50:18.318831Z",
     "start_time": "2021-06-17T12:50:03.210099Z"
    }
   },
   "outputs": [],
   "source": [
    "validation(retinanet, 'Test', start_round,60,2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T12:50:33.522895Z",
     "start_time": "2021-06-17T12:50:18.334668Z"
    }
   },
   "outputs": [],
   "source": [
    "validation(retinanet, 'Test', start_round,50,2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T12:50:48.825888Z",
     "start_time": "2021-06-17T12:50:33.537992Z"
    }
   },
   "outputs": [],
   "source": [
    "validation(retinanet, 'Test', start_round,40,2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T02:08:40.921220Z",
     "start_time": "2021-06-17T02:08:29.137219Z"
    }
   },
   "outputs": [],
   "source": [
    "validation(retinanet, 'Test', start_round,50,2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T02:12:41.553421Z",
     "start_time": "2021-06-17T02:12:29.626870Z"
    }
   },
   "outputs": [],
   "source": [
    "validation(retinanet, 'Test', start_round,40,2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T02:51:21.763392Z",
     "start_time": "2021-06-09T02:51:09.165075Z"
    }
   },
   "outputs": [],
   "source": [
    "validation(retinanet, 'Test', start_round,40,2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T04:35:16.453699Z",
     "start_time": "2021-06-03T04:34:59.535893Z"
    }
   },
   "outputs": [],
   "source": [
    "validation(retinanet, 'Test', start_round,40,2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T02:49:56.200933Z",
     "start_time": "2021-06-09T02:49:43.968747Z"
    }
   },
   "outputs": [],
   "source": [
    "validation(retinanet, 'Test', start_round,50,2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T02:48:27.916781Z",
     "start_time": "2021-06-03T02:48:08.621821Z"
    }
   },
   "outputs": [],
   "source": [
    "validation(retinanet, 'Test', start_round,50,2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:07:30.417786Z",
     "start_time": "2021-06-17T17:07:29.592171Z"
    }
   },
   "outputs": [],
   "source": [
    "true, pred = validation(retinanet, 'Test', start_round,50, 2, 2007, False, [12], 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:08:16.544992Z",
     "start_time": "2021-06-17T17:08:16.281985Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test = CocoDataset_inOrder(os.path.join(root_path, 'DataSet', 'VOC{}'.format(2007)), set_name=\"TestVoc2007\", dataset = 'voc', \n",
    "                transform=transforms.Compose([Normalizer(), Resizer()]), \n",
    "                start_round=1, data_split = \"15+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T12:18:01.049963Z",
     "start_time": "2021-06-14T12:18:01.043253Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test.seen_class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T12:18:18.388468Z",
     "start_time": "2021-06-14T12:18:18.381895Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test.cocoHelper.catNameToId('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:08:22.845183Z",
     "start_time": "2021-06-17T17:08:18.263896Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "import random\n",
    "\n",
    "# Draws a caption above the box in an image\n",
    "def draw_caption(image, box, caption, color=(255, 0, 255)):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, ( b[0] , b[1] + int((b[3] - b[1]) / 2) ), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 1)\n",
    "\n",
    "    \n",
    "target_cat_id = 6\n",
    "path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2007/images'\n",
    "\n",
    "non_target = list(set(pred.getImgIds()) & set(true.getImgIds(catIds=[target_cat_id])))\n",
    "random.shuffle(non_target)\n",
    "#non12 = true.getImgIds(catIds=[catId])\n",
    "\n",
    "i = 0\n",
    "flag = False\n",
    "flag2 = False\n",
    "for imgId in non_target:\n",
    "    print(imgId)\n",
    "    flag = False\n",
    "    flag2 = False\n",
    "    im = cv2.imread(os.path.join(path, os.path.join(path, \"%06d.jpg\" % (int(imgId)))))\n",
    "    gd_anns = true.loadAnns(true.getAnnIds(imgIds=[imgId]))\n",
    "    for ann in pred.loadAnns(pred.getAnnIds(imgIds=[imgId])):\n",
    "        flag2 = True\n",
    "        #print(ann)\n",
    "        box = ann['bbox']\n",
    "\n",
    "        x1, y1, w, h = box\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        start_p = (int(x1) , int(y1))\n",
    "        end_p = (int(x2) , int(y2))\n",
    "\n",
    "        if ann['score'] >= 0.5 or len(gd_anns) == 1:\n",
    "            if ann['category_id'] == target_cat_id:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)))\n",
    "                color = (0,255,0)\n",
    "            else:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)),(0, 255, 255))\n",
    "                name = dataset_test.cocoHelper.catIdToName(ann['category_id'])[0]\n",
    "                draw_caption(im,(x1, y1 - 50, x2, y2),name,(0, 255, 0))\n",
    "                color = (0,0,255)\n",
    "            cv2.rectangle(im, start_p, end_p, color, thickness=2)\n",
    "    \n",
    "    test = 0\n",
    "    for ann in true.loadAnns(true.getAnnIds(imgIds=[imgId])):\n",
    "        test += 1\n",
    "        \n",
    "        box = ann['bbox']\n",
    "\n",
    "        x1, y1, w, h = box\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        start_p = (int(x1) , int(y1))\n",
    "        end_p = (int(x2) , int(y2))\n",
    "\n",
    "        cv2.rectangle(im, start_p, end_p, (255,0,0), thickness=2)\n",
    "    print(test)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    imshow(im)\n",
    "    i += 1\n",
    "    if i == 12:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T12:16:38.204790Z",
     "start_time": "2021-06-14T12:16:33.487879Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "import random\n",
    "\n",
    "# Draws a caption above the box in an image\n",
    "def draw_caption(image, box, caption, color=(255, 0, 255)):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, ( b[0] , b[1] + int((b[3] - b[1]) / 2) ), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 1)\n",
    "\n",
    "    \n",
    "target_cat_id = 6\n",
    "path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2007/images'\n",
    "\n",
    "non_target = list(set(pred.getImgIds()) & set(true.getImgIds(catIds=[6])))\n",
    "random.shuffle(non_target)\n",
    "#non12 = true.getImgIds(catIds=[catId])\n",
    "\n",
    "i = 0\n",
    "flag = False\n",
    "flag2 = False\n",
    "for imgId in non_target:\n",
    "    print(imgId)\n",
    "    flag = False\n",
    "    flag2 = False\n",
    "    im = cv2.imread(os.path.join(path, os.path.join(path, \"%06d.jpg\" % (int(imgId)))))\n",
    "    gd_anns = true.loadAnns(true.getAnnIds(imgIds=[imgId]))\n",
    "    for ann in pred.loadAnns(pred.getAnnIds(imgIds=[imgId])):\n",
    "        flag2 = True\n",
    "        #print(ann)\n",
    "        box = ann['bbox']\n",
    "\n",
    "        x1, y1, w, h = box\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        start_p = (int(x1) , int(y1))\n",
    "        end_p = (int(x2) , int(y2))\n",
    "\n",
    "        if ann['score'] >= 0.5 or len(gd_anns) == 1:\n",
    "            if ann['category_id'] == catId:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)))\n",
    "                color = (0,255,0)\n",
    "            else:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)),(0, 255, 255))\n",
    "                name = dataset_test.cocoHelper.catIdToName(ann['category_id'])[0]\n",
    "                draw_caption(im,(x1, y1 - 50, x2, y2),name,(0, 255, 0))\n",
    "                color = (0,0,255)\n",
    "            cv2.rectangle(im, start_p, end_p, color, thickness=2)\n",
    "    \n",
    "    test = 0\n",
    "    for ann in true.loadAnns(true.getAnnIds(imgIds=[imgId])):\n",
    "        test += 1\n",
    "        \n",
    "        box = ann['bbox']\n",
    "\n",
    "        x1, y1, w, h = box\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        start_p = (int(x1) , int(y1))\n",
    "        end_p = (int(x2) , int(y2))\n",
    "\n",
    "        cv2.rectangle(im, start_p, end_p, (255,0,0), thickness=2)\n",
    "    print(test)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    imshow(im)\n",
    "    i += 1\n",
    "    if i == 12:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T12:20:29.393065Z",
     "start_time": "2021-06-14T12:20:24.513732Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "import random\n",
    "\n",
    "# Draws a caption above the box in an image\n",
    "def draw_caption(image, box, caption, color=(255, 0, 255)):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, ( b[0] , b[1] + int((b[3] - b[1]) / 2) ), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 1)\n",
    "\n",
    "    \n",
    "target_cat_id = 2\n",
    "path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2007/images'\n",
    "\n",
    "non_target = list(set(pred.getImgIds()) & set(true.getImgIds(catIds=[target_cat_id])))\n",
    "random.shuffle(non_target)\n",
    "#non12 = true.getImgIds(catIds=[catId])\n",
    "\n",
    "i = 0\n",
    "flag = False\n",
    "flag2 = False\n",
    "for imgId in non_target:\n",
    "    print(imgId)\n",
    "    flag = False\n",
    "    flag2 = False\n",
    "    im = cv2.imread(os.path.join(path, os.path.join(path, \"%06d.jpg\" % (int(imgId)))))\n",
    "    gd_anns = true.loadAnns(true.getAnnIds(imgIds=[imgId]))\n",
    "    for ann in pred.loadAnns(pred.getAnnIds(imgIds=[imgId])):\n",
    "        flag2 = True\n",
    "        #print(ann)\n",
    "        box = ann['bbox']\n",
    "\n",
    "        x1, y1, w, h = box\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        start_p = (int(x1) , int(y1))\n",
    "        end_p = (int(x2) , int(y2))\n",
    "\n",
    "        if ann['score'] >= 0.5 or len(gd_anns) == 1:\n",
    "            if ann['category_id'] == 6:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)))\n",
    "                color = (0,255,0)\n",
    "            else:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)),(0, 255, 255))\n",
    "                name = dataset_test.cocoHelper.catIdToName(ann['category_id'])[0]\n",
    "                draw_caption(im,(x1, y1 - 50, x2, y2),name,(0, 255, 0))\n",
    "                color = (0,0,255)\n",
    "            cv2.rectangle(im, start_p, end_p, color, thickness=2)\n",
    "    \n",
    "    test = 0\n",
    "    for ann in true.loadAnns(true.getAnnIds(imgIds=[imgId])):\n",
    "        test += 1\n",
    "        \n",
    "        box = ann['bbox']\n",
    "\n",
    "        x1, y1, w, h = box\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        start_p = (int(x1) , int(y1))\n",
    "        end_p = (int(x2) , int(y2))\n",
    "\n",
    "        cv2.rectangle(im, start_p, end_p, (255,0,0), thickness=2)\n",
    "    print(test)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    imshow(im)\n",
    "    i += 1\n",
    "    if i == 12:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:09:23.651216Z",
     "start_time": "2021-06-17T17:09:18.845337Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "import random\n",
    "\n",
    "# Draws a caption above the box in an image\n",
    "def draw_caption(image, box, caption, color=(255, 0, 255)):\n",
    "    b = np.array(box).astype(int)\n",
    "    cv2.putText(image, caption, ( b[0] , b[1] + int((b[3] - b[1]) / 2) ), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 1)\n",
    "\n",
    "    \n",
    "target_cat_id = 6\n",
    "path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2007/images'\n",
    "\n",
    "non_target = list(set(true.getImgIds()) - set(true.getImgIds(catIds=[target_cat_id])))\n",
    "random.shuffle(non_target)\n",
    "#non12 = true.getImgIds(catIds=[catId])\n",
    "\n",
    "i = 0\n",
    "flag = False\n",
    "flag2 = False\n",
    "for imgId in non_target:\n",
    "    flag = False\n",
    "    flag2 = False\n",
    "    for ann in pred.loadAnns(pred.getAnnIds(imgIds=[imgId])):\n",
    "        if ann['category_id'] == target_cat_id:\n",
    "            im = cv2.imread(os.path.join(path, os.path.join(path, \"%06d.jpg\" % (int(imgId)))))\n",
    "            flag = True\n",
    "            break\n",
    "        \n",
    "    if flag:\n",
    "        for ann in pred.loadAnns(pred.getAnnIds(imgIds=[imgId])):\n",
    "            flag2 = True\n",
    "            #print(ann)\n",
    "            box = ann['bbox']\n",
    "\n",
    "            x1, y1, w, h = box\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "            start_p = (int(x1) , int(y1))\n",
    "            end_p = (int(x2) , int(y2))\n",
    " \n",
    "            if ann['category_id'] == target_cat_id:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)))\n",
    "                color = (0,255,0)\n",
    "            else:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)),(0, 255, 255))\n",
    "                color = (0,0,255)\n",
    "            cv2.rectangle(im, start_p, end_p, color, thickness=2)\n",
    "    if flag2:\n",
    "        for ann in true.loadAnns(true.getAnnIds(imgIds=[imgId])):\n",
    "#             if ann['category_id'] == catId:\n",
    "            box = ann['bbox']\n",
    "\n",
    "            x1, y1, w, h = box\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "            start_p = (int(x1) , int(y1))\n",
    "            end_p = (int(x2) , int(y2))\n",
    "            \n",
    "            cv2.rectangle(im, start_p, end_p, (255,0,0), thickness=2)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        imshow(im)\n",
    "        i += 1\n",
    "    if i == 12:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T08:58:26.631067Z",
     "start_time": "2021-06-14T08:58:26.541439Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "import random\n",
    "\n",
    "# Draws a caption above the box in an image\n",
    "def draw_caption(image, box, caption, color):\n",
    "    b = np.array(box).astype(int)\n",
    "    #cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 2)\n",
    "    cv2.putText(image, caption, (b[0] + int((b[2] - b[0]) /  4), b[1] + int((b[3] - b[1]) / 2) ), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 1)\n",
    "\n",
    "    \n",
    "catId = 6\n",
    "path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2007/images'\n",
    "\n",
    "non12 = list(set(true.getImgIds()) - set(true.getImgIds(catIds=[catId])))\n",
    "\n",
    "#non12 = true.getImgIds(catIds=[catId])\n",
    "\n",
    "i = 0\n",
    "flag = False\n",
    "flag2 = False\n",
    "random.shuffle(non12)\n",
    "for imgId in non12:\n",
    "    flag = False\n",
    "    flag2 = False\n",
    "    for ann in pred.loadAnns(pred.getAnnIds(imgIds=[imgId])):\n",
    "        if ann['category_id'] == catId and flag == False:\n",
    "            im = cv2.imread(os.path.join(path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "            flag = True\n",
    "            break\n",
    "        \n",
    "        \n",
    "    if flag:\n",
    "        for ann in pred.loadAnns(pred.getAnnIds(imgIds=[imgId])):\n",
    "            flag2 = True\n",
    "            #print(ann)\n",
    "            box = ann['bbox']\n",
    "\n",
    "            x1, y1, w, h = box\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "            start_p = (int(x1) , int(y1))\n",
    "            end_p = (int(x2) , int(y2))\n",
    " \n",
    "            if ann['category_id'] == catId:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)), (0,255,0))\n",
    "                color = (0,255,0)\n",
    "            else:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)), (0,0,255))\n",
    "                color = (0,0,255)\n",
    "            cv2.rectangle(im, start_p, end_p, color, thickness=2)\n",
    "    if flag2:\n",
    "        for ann in true.loadAnns(true.getAnnIds(imgIds=[imgId])):\n",
    "#             if ann['category_id'] == catId:\n",
    "            box = ann['bbox']\n",
    "\n",
    "            x1, y1, w, h = box\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "            start_p = (int(x1) , int(y1))\n",
    "            end_p = (int(x2) , int(y2))\n",
    "            \n",
    "            cv2.rectangle(im, start_p, end_p, (255,0,0), thickness=2)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        imshow(im)\n",
    "        i+= 1\n",
    "    if i == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:46:45.698094Z",
     "start_time": "2021-06-02T09:46:45.667386Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow\n",
    "import random\n",
    "\n",
    "# Draws a caption above the box in an image\n",
    "def draw_caption(image, box, caption, color):\n",
    "    b = np.array(box).astype(int)\n",
    "    #cv2.putText(image, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 0), 2)\n",
    "    cv2.putText(image, caption, (b[0] + int((b[2] - b[0]) /  4), b[1] + int((b[3] - b[1]) / 2) ), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 1)\n",
    "\n",
    "    \n",
    "catId = 6\n",
    "path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2007/images'\n",
    "\n",
    "# non12 = list(set(true.getImgIds()) - set(true.getImgIds(catIds=[catId])))\n",
    "\n",
    "#non12 = true.getImgIds(catIds=[catId])\n",
    "\n",
    "i = 0\n",
    "flag = False\n",
    "flag2 = False\n",
    "# random.shuffle(non12)\n",
    "non12 = visual_img\n",
    "for imgId in non12:\n",
    "    flag = False\n",
    "    flag2 = False\n",
    "    for ann in pred.loadAnns(pred.getAnnIds(imgIds=[imgId])):\n",
    "        if ann['category_id'] == catId and flag == False:\n",
    "            im = cv2.imread(os.path.join(path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "            flag = True\n",
    "            break\n",
    "        \n",
    "        \n",
    "    if flag:\n",
    "        for ann in pred.loadAnns(pred.getAnnIds(imgIds=[imgId])):\n",
    "            flag2 = True\n",
    "            #print(ann)\n",
    "            box = ann['bbox']\n",
    "\n",
    "            x1, y1, w, h = box\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "            start_p = (int(x1) , int(y1))\n",
    "            end_p = (int(x2) , int(y2))\n",
    " \n",
    "            if ann['category_id'] == catId:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)), (0,255,0))\n",
    "                color = (0,255,0)\n",
    "            else:\n",
    "                draw_caption(im,(x1, y1, x2, y2),str(round(ann['score'],3)), (0,0,255))\n",
    "                color = (0,0,255)\n",
    "            cv2.rectangle(im, start_p, end_p, color, thickness=2)\n",
    "    if flag2:\n",
    "        for ann in true.loadAnns(true.getAnnIds(imgIds=[imgId])):\n",
    "#             if ann['category_id'] == catId:\n",
    "            box = ann['bbox']\n",
    "\n",
    "            x1, y1, w, h = box\n",
    "            x2 = x1 + w\n",
    "            y2 = y1 + h\n",
    "            start_p = (int(x1) , int(y1))\n",
    "            end_p = (int(x2) , int(y2))\n",
    "            \n",
    "            cv2.rectangle(im, start_p, end_p, (255,0,0), thickness=2)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        imshow(im)\n",
    "        i+= 1\n",
    "    if i == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T02:00:21.015751Z",
     "start_time": "2021-06-06T02:00:21.011592Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T02:07:11.008529Z",
     "start_time": "2021-06-06T02:07:10.993781Z"
    }
   },
   "outputs": [],
   "source": [
    "test = torch.ones(4,20)\n",
    "test[0,0] = 0\n",
    "test[1,0] = 0\n",
    "\n",
    "test[3,10] = 0\n",
    "print(test)\n",
    "test = torch.mean(test, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T02:09:47.481326Z",
     "start_time": "2021-06-06T02:09:47.472551Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.zeros(test.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T02:06:16.900016Z",
     "start_time": "2021-06-06T02:06:16.891654Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.stack([test,test]).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:shiang]",
   "language": "python",
   "name": "conda-env-shiang-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
