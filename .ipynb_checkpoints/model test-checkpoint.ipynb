{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T02:54:14.101357Z",
     "start_time": "2021-06-25T02:54:09.666321Z"
    },
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from retinanet import model\n",
    "from retinanet import coco_eval\n",
    "from retinanet.dataloader import CocoDataset_inOrder,rehearsal_DataSet, collater, Resizer, AspectRatioBasedSampler, Augmenter, Normalizer\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import torch\n",
    "root_path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/'\n",
    "method = 'w_distillation'\n",
    "data_split = '15+1'\n",
    "start_round = 1\n",
    "batch_size = 1\n",
    "\n",
    "checkpoint_epoch = 50\n",
    "\n",
    "def checkDir(path):\n",
    "    \"\"\"check whether directory exists or not.If not, then create it \n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "def get_checkpoint_path(method, now_round, epoch, data_split =\"None\"):\n",
    "    global root_path\n",
    "    # global data_split\n",
    "    \n",
    "    \n",
    "    checkDir(os.path.join(root_path, 'model', method, 'round{}'.format(now_round)))\n",
    "    checkDir(os.path.join(root_path, 'model', method, 'round{}'.format(now_round), data_split))\n",
    "    \n",
    "    path = os.path.join(root_path, 'model', method, 'round{}'.format(now_round), data_split,'voc_retinanet_{}_checkpoint.pt'.format(epoch))\n",
    "    return path\n",
    "\n",
    "\n",
    "def readCheckpoint(method, now_round, epoch, data_split, retinanet, optimizer = None, scheduler = None):\n",
    "    print('readcheckpoint at Round{} Epoch{}'.format(now_round, epoch))\n",
    "    prev_checkpoint = torch.load(get_checkpoint_path(method, now_round, epoch, data_split))\n",
    "    retinanet.load_state_dict(prev_checkpoint['model_state_dict'])\n",
    "    if optimizer != None:\n",
    "        optimizer.load_state_dict(prev_checkpoint['optimizer_state_dict'])\n",
    "    if scheduler != None:\n",
    "        scheduler.load_state_dict(prev_checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "\n",
    "\n",
    "# coco_path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012'\n",
    "\n",
    "\n",
    "\n",
    "# dataset_train = CocoDataset_inOrder(coco_path, set_name='TrainVoc2012', dataset = 'voc',\n",
    "#                                     transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]),\n",
    "#                                    data_split=data_split, start_round=start_round)\n",
    "\n",
    "# # dataset_val = CocoDataset_inOrder(os.path.join(root_path, 'DataSet', 'VOC2012'), set_name=\"ValVoc2012\", dataset = 'voc', \n",
    "# #                 transform=transforms.Compose([Normalizer(), Resizer()]), \n",
    "# #                 start_round=1, data_split = \"20\")\n",
    "\n",
    "dataset_train = CocoDataset_inOrder(os.path.join(root_path, 'DataSet', 'VOC2012'), set_name='TrainVoc2012', dataset = 'voc',\n",
    "                                    transform=transforms.Compose([Normalizer(), Resizer()]),\n",
    "                                   data_split=data_split, start_round=start_round)\n",
    "retinanet = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "retinanet.cuda()\n",
    "\n",
    "#sampler = AspectRatioBasedSampler(dataset_train, batch_size = batch_size, drop_last=False)\n",
    "# # dataloader_train = DataLoader(dataset_train, num_workers=2, collate_fn=collater, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(retinanet.parameters(), lr=1e-5)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "# loss_hist = collections.deque(maxlen=500)\n",
    "\n",
    "readCheckpoint(method, start_round, checkpoint_epoch,data_split, retinanet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T02:49:27.708209Z",
     "start_time": "2021-06-25T02:49:27.670266Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import numpy as np\n",
    "def collater(data):\n",
    "\n",
    "    imgs = [s['img'] for s in data]\n",
    "    annots = [s['annot'] for s in data]\n",
    "    scales = [s['scale'] for s in data]\n",
    "        \n",
    "    widths = [int(s.shape[0]) for s in imgs]\n",
    "    heights = [int(s.shape[1]) for s in imgs]\n",
    "    batch_size = len(imgs)\n",
    "\n",
    "    max_width = np.array(widths).max()\n",
    "    max_height = np.array(heights).max()\n",
    "\n",
    "    padded_imgs = torch.zeros(batch_size, max_width, max_height, 3)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        img = imgs[i]\n",
    "        padded_imgs[i, :int(img.shape[0]), :int(img.shape[1]), :] = img\n",
    "\n",
    "    max_num_annots = max(annot.shape[0] for annot in annots)\n",
    "    \n",
    "    if max_num_annots > 0:\n",
    "\n",
    "        annot_padded = torch.ones((len(annots), max_num_annots, 5)) * -1\n",
    "\n",
    "        if max_num_annots > 0:\n",
    "            for idx, annot in enumerate(annots):\n",
    "                if annot.shape[0] > 0:\n",
    "                    annot_padded[idx, :annot.shape[0], :] = annot\n",
    "    else:\n",
    "        annot_padded = torch.ones((len(annots), 1, 5)) * -1\n",
    "\n",
    "\n",
    "    padded_imgs = padded_imgs.permute(0, 3, 1, 2)\n",
    "\n",
    "    return {'img': padded_imgs, 'annot': annot_padded, 'scale': scales}\n",
    "\n",
    "class AspectRatioBasedSampler(Sampler):\n",
    "\n",
    "    def __init__(self, data_source, batch_size, drop_last):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.groups = self.group_images()\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.groups)\n",
    "        for group in self.groups:\n",
    "            yield group\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.data_source) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.data_source) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def group_images(self):\n",
    "        # determine the order of the images\n",
    "        order = list(range(len(self.data_source)))\n",
    "        order.sort(key=lambda x: self.data_source.image_aspect_ratio(x))\n",
    "\n",
    "        # divide into groups, one group = one batch\n",
    "        return [[order[x % len(order)] for x in range(i, i + self.batch_size)] for i in range(0, len(order), self.batch_size)]\n",
    "\n",
    "class A_GEM(object):\n",
    "    def __init__(self, model, replay_dataset, batch_sample = 5):\n",
    "        self.memory = replay_dataset\n",
    "        self.model = model\n",
    "        self.batch_sample = batch_sample\n",
    "        self.replay_grad = None\n",
    "        self.update_dataLoader()\n",
    "        \n",
    "    def cal_replay_grad(self, optimizer):\n",
    "        #print(\"calculate replay grad!\")\n",
    "        self.replay_grad = []\n",
    "        #data = self.dataLoader.__iter__().next()\n",
    "        \n",
    "        num_groups = len(self.sampler.groups)\n",
    "        for group in self.sampler.groups:\n",
    "            data = []\n",
    "            for idx in group:\n",
    "                data.append(self.sampler.data_source[idx])\n",
    "            data = collater(data)\n",
    "            temp = []\n",
    "            try:\n",
    "                optimizer.zero_grad()\n",
    "                prev_status = self.model.distill_loss\n",
    "                self.model.distill_loss = False\n",
    "                with torch.cuda.device(0):\n",
    "                    classification_loss, regression_loss = self.model([data['img'].float().cuda(), data['annot'].cuda()])\n",
    "                    classification_loss = classification_loss.mean()\n",
    "                    regression_loss = regression_loss.mean()\n",
    "                    loss = classification_loss + regression_loss\n",
    "                    loss.backward()\n",
    "                    print('Replay Data: Classification loss: {:1.5f} | Regression loss: {:1.5f}'.format(float(classification_loss), float(regression_loss)))\n",
    "                    for name, p in self.model.named_parameters():\n",
    "                        if \"prev_model\" not in name and \"bn\" not in name and p.requires_grad:\n",
    "                            temp.append(p.grad.view(-1))\n",
    "                    \n",
    "                    temp = torch.cat(temp) / num_groups\n",
    "                    if self.replay_grad == []:\n",
    "                        self.replay_grad = temp\n",
    "                    else:\n",
    "                        self.replay_grad += temp\n",
    "                        \n",
    "                        \n",
    "                    del temp\n",
    "                    del classification_loss, regression_loss\n",
    "                optimizer.zero_grad()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "        \n",
    "#             self.cal_replay_grad(optimizer)\n",
    "        self.model.distill_loss = prev_status\n",
    "    \n",
    "    def fix_grad(self):\n",
    "        # cal current gradient\n",
    "        cur_grad = []\n",
    "        for name, p in self.model.named_parameters():\n",
    "            if \"prev_model\" not in name and \"bn\" not in name and p.requires_grad:\n",
    "                cur_grad.append(p.grad.view(-1))\n",
    "        cur_grad = torch.cat(cur_grad)\n",
    "        length_replay = (self.replay_grad * self.replay_grad).sum() # the vector of replay_grad's length \n",
    "        angle = (cur_grad * self.replay_grad).sum() # the two gradient's angle\n",
    "        \n",
    "        \n",
    "        # update grad\n",
    "        if angle < 0:\n",
    "            proj_grad = cur_grad - ((angle / length_replay) * self.replay_grad) # project gradient\n",
    "            #proj_grad = torch.where(torch.ge(angle, 0), cur_grad, proj_grad)\n",
    "            index = 0\n",
    "            for name, p in self.model.named_parameters():\n",
    "                if \"prev_model\" not in name and \"bn\" not in name and p.requires_grad:\n",
    "                    n_param = p.numel()  # number of parameters in [p]\n",
    "                    p.grad.copy_(proj_grad[index:index+n_param].view_as(p))\n",
    "                    index += n_param\n",
    "            del proj_grad\n",
    "        del cur_grad, self.replay_grad\n",
    "            \n",
    "    def update_dataLoader(self):\n",
    "        self.sampler = AspectRatioBasedSampler(self.memory, batch_size = self.batch_sample, drop_last=False)\n",
    "        #self.dataLoader = DataLoader(self.memory, num_workers=2, collate_fn=collater, batch_sampler=sampler) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T02:49:30.035522Z",
     "start_time": "2021-06-25T02:49:29.808510Z"
    }
   },
   "outputs": [],
   "source": [
    "rehearsal_dataset = rehearsal_DataSet('/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012', set_name='TrainVoc2012', dataset = 'voc',\n",
    "                        transform=transforms.Compose([Normalizer(), Resizer()]), \n",
    "                        data_split = \"15+1\",method = \"random\", per_num = 2)\n",
    "rehearsal_dataset.reset_by_round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T02:50:01.633463Z",
     "start_time": "2021-06-25T02:50:01.628460Z"
    }
   },
   "outputs": [],
   "source": [
    "sampler = AspectRatioBasedSampler(rehearsal_dataset, batch_size = 5, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T02:52:33.127966Z",
     "start_time": "2021-06-25T02:52:32.767594Z"
    }
   },
   "outputs": [],
   "source": [
    "for group in sampler.groups:\n",
    "    data = []\n",
    "    for idx in group:\n",
    "        data.append(sampler.data_source[idx])\n",
    "    data = collater(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T09:22:42.045660Z",
     "start_time": "2021-06-24T09:22:42.039987Z"
    }
   },
   "outputs": [],
   "source": [
    "agem = A_GEM(retinanet, rehearsal_dataset, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T09:24:15.133246Z",
     "start_time": "2021-06-24T09:24:12.651911Z"
    }
   },
   "outputs": [],
   "source": [
    "agem.cal_replay_grad(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改sample的data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T08:02:57.970519Z",
     "start_time": "2021-06-25T08:02:56.967163Z"
    }
   },
   "outputs": [],
   "source": [
    "from retinanet.dataloader import CocoDataset_inOrder,rehearsal_DataSet, collater, Resizer, AspectRatioBasedSampler, Augmenter, Normalizer\n",
    "from torchvision import transforms\n",
    "rehearsal_dataset = rehearsal_DataSet('/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012', set_name='TrainVoc2012', dataset = 'voc',\n",
    "                        transform=transforms.Compose([Normalizer(), Resizer()]), \n",
    "                        data_split = \"15+1\",method = \"random\", per_num = 1)\n",
    "rehearsal_dataset.reset_by_round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T08:13:00.275842Z",
     "start_time": "2021-06-25T08:13:00.269848Z"
    }
   },
   "outputs": [],
   "source": [
    "rehearsal_dataset.cocoHelper.catNameToId('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T08:14:23.879500Z",
     "start_time": "2021-06-25T08:14:20.319263Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imgIds = rehearsal_dataset.coco.getImgIds(catIds=17)\n",
    "random.shuffle(imgIds)\n",
    "\n",
    "i = 1\n",
    "for imgId in imgIds:\n",
    "    print(imgId)\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(im)\n",
    "    i += 1\n",
    "    if i == 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T07:37:52.875840Z",
     "start_time": "2021-06-25T07:37:52.866778Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "catIds = rehearsal_dataset.classOrder['id'][0]\n",
    "\n",
    "names = rehearsal_dataset.cocoHelper.catIdToName(catIds)\n",
    "print(names)\n",
    "\n",
    "sample = defaultdict(list)\n",
    "i = 0\n",
    "\n",
    "for name in names:\n",
    "    for _ in range(2):\n",
    "        sample[name].append(rehearsal_dataset.image_ids[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T07:41:44.923777Z",
     "start_time": "2021-06-25T07:41:44.916738Z"
    }
   },
   "outputs": [],
   "source": [
    "rehearsal_dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T08:15:07.488110Z",
     "start_time": "2021-06-25T08:15:07.478660Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = {'person': [2008001302],\n",
    "         'car': [2010004059],\n",
    "         'bicycle': [2008004603],\n",
    "         'bus':     [2009004871], \n",
    "         'motorbike': [2010004848],\n",
    "         'aeroplane': [2011001871],\n",
    "         'boat':  [2008008616],\n",
    "         'chair': [2010002870],\n",
    "         'bottle': [2009005057],\n",
    "         'diningtable': [2010003078],\n",
    "         'bird': [2008006923],\n",
    "         'cat': [2009001948],\n",
    "         'cow': [2009003510],\n",
    "         'dog': [2008001479],\n",
    "         'horse': [2010004247]}\n",
    "\n",
    "samples = []\n",
    "for v in sample.values():\n",
    "    samples.extend(v)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T08:15:11.813133Z",
     "start_time": "2021-06-25T08:15:09.058319Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "per_num =1\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4*per_num,50))\n",
    "gs = gridspec.GridSpec(len(samples) // per_num, per_num)\n",
    "i, j = 0, 0\n",
    "for imgId in samples:\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.subplot(gs[i,j])\n",
    "    plt.imshow(im)\n",
    "    j += 1\n",
    "    if j == per_num:\n",
    "        j = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T07:45:06.858444Z",
     "start_time": "2021-06-25T07:45:06.846053Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = {'person': [2008002080, 2008001302],\n",
    "         'car': [2010004059, 2010001043],\n",
    "         'bicycle': [2009004340, 2008004603],\n",
    "         'bus':     [2009004871, 2009004383], \n",
    "         'motorbike': [2010004848, 2011000233],\n",
    "         'aeroplane': [2009001541, 2008007629],\n",
    "         'boat':  [2008002850, 2008008616],\n",
    "         'chair': [2010004660, 2010002870],\n",
    "         'bottle': [2008006004, 2009005057],\n",
    "         'diningtable': [2011002818, 2010003078],\n",
    "         'bird': [2009001751, 2010003929],\n",
    "         'cat': [2009005037, 2009005177],\n",
    "         'cow': [2008008521, 2008008121],\n",
    "         'dog': [2010000484, 2008001479],\n",
    "         'horse': [2010004247, 2009001147]}\n",
    "\n",
    "samples = []\n",
    "for v in sample.values():\n",
    "    samples.extend(v)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T07:44:49.653467Z",
     "start_time": "2021-06-25T07:44:45.396872Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "per_num =2\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4*per_num,50))\n",
    "gs = gridspec.GridSpec(len(samples) // per_num, per_num)\n",
    "i, j = 0, 0\n",
    "for imgId in samples:\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.subplot(gs[i,j])\n",
    "    plt.imshow(im)\n",
    "    j += 1\n",
    "    if j == per_num:\n",
    "        j = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T05:14:01.230915Z",
     "start_time": "2021-06-15T05:14:01.208621Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.gridspec as gridspec\n",
    "i = 0\n",
    "cat_name = 'motorbike'\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "future_class_id = []\n",
    "for i in range(1, len(rehearsal_dataset.classOrder['id'])):\n",
    "    future_class_id.extend(rehearsal_dataset.classOrder['id'][i])\n",
    "\n",
    "future_imgIds = set(rehearsal_dataset.cocoHelper.getImgIdFromCats(future_class_id))\n",
    "\n",
    "imgIds = rehearsal_dataset.cocoHelper.getImgIdFromCats(catIds=rehearsal_dataset.cocoHelper.catNameToId(cat_name))\n",
    "\n",
    "imgIds = list(set(imgIds) - set(future_imgIds)) \n",
    "\n",
    "random.shuffle(imgIds)\n",
    "for imgId in imgIds:\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.figure()\n",
    "    plt.title(imgId)\n",
    "    plt.imshow(im)\n",
    "    i += 1\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T08:03:12.976138Z",
     "start_time": "2021-06-25T08:03:10.788595Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import os\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "catIds = rehearsal_dataset.classOrder['id'][0]\n",
    "names = rehearsal_dataset.cocoHelper.catIdToName(catIds)\n",
    "print(names)\n",
    "per_num = 1\n",
    "\n",
    "plt.figure(figsize=(4*per_num,50))\n",
    "gs = gridspec.GridSpec(len(rehearsal_dataset.image_ids) // per_num, per_num)\n",
    "i, j = 0, 0\n",
    "for imgId in rehearsal_dataset.image_ids:\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.subplot(gs[i,j])\n",
    "    plt.imshow(im)\n",
    "    j += 1\n",
    "    if j == per_num:\n",
    "        j = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T12:47:27.196444Z",
     "start_time": "2021-06-14T12:47:22.813350Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "names = [name for name in rehearsal_dataset.classOrder['id'][:15]]\n",
    "print(names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,50))\n",
    "gs = gridspec.GridSpec(len(rehearsal_dataset.image_ids) // 2, 2)\n",
    "i, j = 0, 0\n",
    "for imgId in rehearsal_dataset.image_ids:\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.subplot(gs[i,j])\n",
    "    plt.imshow(im)\n",
    "    j += 1\n",
    "    if j == 2:\n",
    "        j = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T16:20:34.252094Z",
     "start_time": "2021-06-06T16:20:27.947444Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "names = [name for name in rehearsal_dataset.classOrder['name'][:15]]\n",
    "print(names)\n",
    "for imgId in rehearsal_dataset.image_ids:\n",
    "    print(imgId)\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.figure()\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:34:06.117883Z",
     "start_time": "2021-06-06T15:33:59.922793Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "\n",
    "names = [name for name in rehearsal_dataset.classOrder['name'][:15]]\n",
    "print(names)\n",
    "for imgId in rehearsal_dataset.image_ids:\n",
    "\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.figure()\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 檢查模型間參數的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:08:15.286291Z",
     "start_time": "2021-06-02T09:08:09.989451Z"
    }
   },
   "outputs": [],
   "source": [
    "retinanet = model.resnet50(num_classes=16, pretrained=True)\n",
    "retinanet_upper = model.resnet50(num_classes=16, pretrained=True)\n",
    "retinanet15 = model.resnet50(num_classes=15, pretrained=True)\n",
    "readCheckpoint(\"w_distillation\", now_round = 2, epoch = 50, data_split=\"15+1\",retinanet=retinanet)\n",
    "readCheckpoint(\"special_try\", now_round = 1, epoch = 50, data_split=\"custom\",retinanet=retinanet_upper)\n",
    "readCheckpoint(\"w_distillation\", now_round = 1, epoch = 50, data_split=\"15+1\",retinanet=retinanet15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:08:15.400303Z",
     "start_time": "2021-06-02T09:08:15.396441Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_names(model):\n",
    "    names = []\n",
    "    for name,parameters in model.named_parameters():\n",
    "        names.append(name)\n",
    "    return names\n",
    "names = get_names(retinanet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:11:59.977551Z",
     "start_time": "2021-06-02T09:11:59.158315Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "MSE = nn.MSELoss()\n",
    "L1 = nn.L1Loss()\n",
    "\n",
    "diffs_for_15 = defaultdict(float)\n",
    "diffs = defaultdict(float)\n",
    "for name in names:\n",
    "    if \"classificationModel.output\" not in name:\n",
    "        diff = MSE(retinanet_upper.state_dict()[name], retinanet15.state_dict()[name])\n",
    "        diffs_for_15[name] = float(diff)\n",
    "    diff = MSE(retinanet.state_dict()[name], retinanet_upper.state_dict()[name])\n",
    "    diffs[name] = float(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:28:38.531105Z",
     "start_time": "2021-06-02T09:28:38.522730Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_rank(diffs):\n",
    "    diffs_keys = [key for key in diffs.keys()]\n",
    "    diffs_values = list(diffs.values())\n",
    "    ascending = sorted(range(len(diffs)), key=lambda k: diffs_values[k])\n",
    "    \n",
    "    num = 100\n",
    "    \n",
    "    for idx in ascending[len(ascending) - num:]:\n",
    "        print(diffs_keys[idx], diffs_values[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算所有data loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:43:56.995758Z",
     "start_time": "2021-05-27T13:35:11.543629Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "retinanet.train()\n",
    "retinanet.freeze_bn()\n",
    "\n",
    "dataset = dataset_train\n",
    "\n",
    "fail_id = []\n",
    "losses = collections.defaultdict(list)\n",
    "\n",
    "for idx, data in enumerate(dataset):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.device(0):\n",
    "            if torch.cuda.is_available():\n",
    "                classification_loss, regression_loss = retinanet([data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0), data['annot'].cuda().unsqueeze(dim=0)])\n",
    "            else:\n",
    "                print('not have gpu')\n",
    "                break\n",
    "\n",
    "            classification_loss = classification_loss.mean()\n",
    "            regression_loss = regression_loss.mean()\n",
    "\n",
    "            img_id = dataset.image_ids[idx]\n",
    "\n",
    "\n",
    "            classification_loss = float(classification_loss)\n",
    "            regression_loss = float(regression_loss)\n",
    "            loss = classification_loss + regression_loss\n",
    "\n",
    "            losses[img_id] = [classification_loss, regression_loss, loss]\n",
    "\n",
    "            #optimizer.step()\n",
    "            loss_hist.append(float(loss))\n",
    "\n",
    "            #epoch_loss.append(float(loss))\n",
    "            end = time.time()\n",
    "\n",
    "            print('Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f} | Spend Time:{:1.2f}s'.format(\n",
    "                                              '50', \n",
    "                                              idx, \n",
    "                                              float(classification_loss), \n",
    "                                              float(regression_loss), \n",
    "                                              np.mean(loss_hist),\n",
    "                                              end - start))\n",
    "            del classification_loss\n",
    "            del regression_loss\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        fail_id.append(idx)\n",
    "        continue\n",
    "\n",
    "print('fail_id:',fail_id)\n",
    "\n",
    "\n",
    "with open(os.path.join(\"/\".join(get_checkpoint_path(method, 1, 50).split('/')[:-1]), 'losses.pickle'), 'wb') as f:\n",
    "    pickle.dump(losses, f)\n",
    "#print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:13:50.683846Z",
     "start_time": "2021-06-06T15:13:50.595229Z"
    }
   },
   "outputs": [],
   "source": [
    "img = dataset_train.load_image(74)\n",
    "ann = dataset_train.load_annotations(74)\n",
    "data = {'img': img, 'annot': ann}\n",
    "data = dataset_train.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:16:08.944527Z",
     "start_time": "2021-06-06T15:16:08.937293Z"
    }
   },
   "outputs": [],
   "source": [
    "data['annot'].cuda().unsque`eze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:12:23.923486Z",
     "start_time": "2021-06-06T15:12:23.916190Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train.cocoHelper.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:13:55.381660Z",
     "start_time": "2021-06-06T15:13:55.315557Z"
    }
   },
   "outputs": [],
   "source": [
    "retinanet.each_cat_loss = True\n",
    "classification_loss, _ = retinanet([data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0), data['annot'].cuda().unsqueeze(dim=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:11:29.945048Z",
     "start_time": "2021-06-06T15:11:29.936988Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分別為每個類別計算loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T14:46:42.703754Z",
     "start_time": "2021-06-06T14:37:59.732942Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "retinanet.train()\n",
    "retinanet.freeze_bn()\n",
    "\n",
    "dataset = dataset_train\n",
    "\n",
    "fail_id = []\n",
    "losses = [collections.defaultdict() for _ in dataset.seen_class_id]\n",
    "\n",
    "retinanet.each_cat_loss = True\n",
    "for idx, data in enumerate(dataset):\n",
    "\n",
    "    try:\n",
    "        with torch.cuda.device(0):\n",
    "            if torch.cuda.is_available():\n",
    "                classification_loss, _ = retinanet([data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0), data['annot'].cuda().unsqueeze(dim=0)])\n",
    "            else:\n",
    "                print('not have gpu')\n",
    "                break\n",
    "\n",
    "\n",
    "            img_id = dataset.image_ids[idx]\n",
    "\n",
    "            for key in classification_loss.keys():\n",
    "                losses[key][img_id] = float(np.mean(classification_loss[key]))\n",
    "\n",
    "            print(idx)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        fail_id.append(idx)\n",
    "        continue\n",
    "\n",
    "print('fail_id:',fail_id)\n",
    "\n",
    "\n",
    "with open(os.path.join(\"/\".join(get_checkpoint_path(method, 1, 50,data_split).split('/')[:-1]), 'losses_each_cat_new.pickle'), 'wb') as f:\n",
    "    pickle.dump(losses, f)\n",
    "#print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T14:36:16.411626Z",
     "start_time": "2021-06-06T14:36:16.405118Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_loss.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T05:34:58.264517Z",
     "start_time": "2021-06-06T05:34:58.209957Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(\"/\".join(get_checkpoint_path(method, 1, 50,data_split).split('/')[:-1]), 'losses_each_cat.pickle'), 'rb') as f:\n",
    "    losses = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T05:35:24.814800Z",
     "start_time": "2021-06-06T05:35:24.807388Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in losses:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:55:41.434110Z",
     "start_time": "2021-05-27T13:55:41.348495Z"
    }
   },
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:48:23.556669Z",
     "start_time": "2021-05-27T13:48:23.548848Z"
    }
   },
   "outputs": [],
   "source": [
    "os.path.join(\"/\".join(get_checkpoint_path(method, 1, 50).split('/')[:-1]), 'losses.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:58:00.745982Z",
     "start_time": "2021-05-27T13:58:00.740224Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = [v[2] for v in losses.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:58:20.940278Z",
     "start_time": "2021-05-27T13:58:20.917729Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:10:11.360151Z",
     "start_time": "2021-04-06T18:10:11.054507Z"
    }
   },
   "outputs": [],
   "source": [
    "method = 'w_distillation'\n",
    "\n",
    "for i in range(50,51,10):\n",
    "    print(np.mean(readCheckpoint(method, 1, i)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:09:05.086275Z",
     "start_time": "2021-04-06T18:09:04.282162Z"
    }
   },
   "outputs": [],
   "source": [
    "method = 'incremental'\n",
    "\n",
    "for i in range(10,31,10):\n",
    "    print(np.mean(readCheckpoint(method, 1, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:05:13.442587Z",
     "start_time": "2021-04-06T18:05:12.170534Z"
    }
   },
   "outputs": [],
   "source": [
    "method = 'incremental'\n",
    "\n",
    "for i in range(10,51,10):\n",
    "    print(np.mean(readCheckpoint(method, 0, i)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(readCheckpoint(method, 0, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T04:32:59.345393Z",
     "start_time": "2021-04-06T04:32:59.339106Z"
    }
   },
   "outputs": [],
   "source": [
    "parts = []\n",
    "\n",
    "for i in range(0,4):\n",
    "    parts.append(retinanet.classificationModel.output.weight.data[i*9: i*9 + 9,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T04:33:01.611318Z",
     "start_time": "2021-04-06T04:33:01.601089Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "output = nn.Conv2d(256, 9 * 20, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T04:36:24.690145Z",
     "start_time": "2021-04-06T04:36:24.679573Z"
    }
   },
   "outputs": [],
   "source": [
    "output.weight.data[0:9,:,:,:] = parts[3]\n",
    "#vehicle(7)\n",
    "for i in range(0,7):\n",
    "    output.weight.data[9 + i*9:9 + i*9 + 9,:,:,:] = parts[0]\n",
    "#furniture(6)\n",
    "for i in range(0,6):\n",
    "    output.weight.data[72 + i*9:72 + i*9 + 9,:,:,:] = parts[1]\n",
    "#animals(6)\n",
    "for i in range(0,6):\n",
    "    output.weight.data[126 + i*9:126 + i*9 + 9,:,:,:] = parts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T04:36:53.559211Z",
     "start_time": "2021-04-06T04:36:53.550539Z"
    }
   },
   "outputs": [],
   "source": [
    "(output.weight.data[72:81,:,:,:] == output.weight.data[81:90,:,:,:]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:29:31.511361Z",
     "start_time": "2021-03-16T17:29:31.372639Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "prev_model = copy.deepcopy(retinanet)\n",
    "retinanet.increase_class(1)\n",
    "\n",
    "retinanet.cuda()\n",
    "prev_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:29:38.239997Z",
     "start_time": "2021-03-16T17:29:38.234111Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "test = torch.ones(2,256,30,30).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:29:39.297163Z",
     "start_time": "2021-03-16T17:29:39.286858Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_out = prev_model.classificationModel.output_act(prev_model.classificationModel.output(test))\n",
    "cur_out = retinanet.classificationModel.output_act(retinanet.classificationModel.output(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:29:52.746312Z",
     "start_time": "2021-03-16T17:29:52.734269Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def change_shape1(out, num_classes):\n",
    "    out1 = out.permute(0, 2, 3, 1)\n",
    "    batch_size, width, height, channels = out1.shape\n",
    "    out1 = out1.view(batch_size, width, height, 9, num_classes)\n",
    "    \n",
    "    return out1.contiguous().view(2, -1, num_classes)\n",
    "def change_shape2(out, num_classes):\n",
    "    out1 = out.permute(0, 2, 3, 1)\n",
    "    batch_size, width, height, channels = out1.shape\n",
    "    out1 = out1.view(batch_size, width, height,num_classes, 9)\n",
    "    \n",
    "    out1 = out1.permute(0, 1, 2, 4, 3)\n",
    "    \n",
    "    return out1.contiguous().view(2, -1, num_classes)\n",
    "prev_out_new1 = change_shape1(prev_out, 19)\n",
    "cur_out_new1 = change_shape1(cur_out, 20)\n",
    "\n",
    "# prev_out_new2 = change_shape2(prev_out, 19)\n",
    "# cur_out_new2 = change_shape2(cur_out, 20)\n",
    "# (prev_out == cur_out[:,:171,:,:]).any()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:shiang]",
   "language": "python",
   "name": "conda-env-shiang-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
