{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T12:30:25.168735Z",
     "start_time": "2021-06-15T12:30:20.660342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "{'id': [[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19], [6], [20], [14], [12], [13]], 'name': [['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person'], ['train'], ['sheep'], ['sofa'], ['pottedplant'], ['tvmonitor']]}\n",
      "dataloader class_num = 15\n",
      "readcheckpoint at Round1 Epoch50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from retinanet import model\n",
    "from retinanet import coco_eval\n",
    "from retinanet.dataloader import CocoDataset_inOrder,rehearsal_DataSet, collater, Resizer, AspectRatioBasedSampler, Augmenter, Normalizer\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import torch\n",
    "root_path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/'\n",
    "method = 'w_distillation'\n",
    "data_split = '15+1'\n",
    "start_round = 1\n",
    "batch_size = 1\n",
    "\n",
    "checkpoint_epoch = 50\n",
    "\n",
    "def checkDir(path):\n",
    "    \"\"\"check whether directory exists or not.If not, then create it \n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "def get_checkpoint_path(method, now_round, epoch, data_split =\"None\"):\n",
    "    global root_path\n",
    "    checkDir(os.path.join(root_path, 'model', method, 'round{}'.format(now_round)))\n",
    "    checkDir(os.path.join(root_path, 'model', method, 'round{}'.format(now_round), data_split))\n",
    "    path = os.path.join(root_path, 'model', method, 'round{}'.format(now_round), data_split,'voc_retinanet_{}_checkpoint.pt'.format(epoch))\n",
    "    return path\n",
    "\n",
    "\n",
    "def readCheckpoint(method, now_round, epoch, data_split, retinanet, optimizer = None, scheduler = None):\n",
    "    print('readcheckpoint at Round{} Epoch{}'.format(now_round, epoch))\n",
    "    prev_checkpoint = torch.load(get_checkpoint_path(method, now_round, epoch, data_split))\n",
    "    retinanet.load_state_dict(prev_checkpoint['model_state_dict'])\n",
    "    if optimizer != None:\n",
    "        optimizer.load_state_dict(prev_checkpoint['optimizer_state_dict'])\n",
    "    if scheduler != None:\n",
    "        scheduler.load_state_dict(prev_checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "dataset_train = CocoDataset_inOrder(os.path.join(root_path, 'DataSet', 'VOC2012'), set_name='TrainVoc2012', dataset = 'voc',\n",
    "                                    transform=transforms.Compose([Normalizer(), Resizer()]),\n",
    "                                   data_split=data_split, start_round=start_round)\n",
    "retinanet = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "retinanet.cuda()\n",
    "\n",
    "readCheckpoint(method, start_round, checkpoint_epoch,data_split, retinanet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T13:41:01.491779Z",
     "start_time": "2021-06-15T13:41:00.101868Z"
    }
   },
   "outputs": [],
   "source": [
    "model = retinanet\n",
    "num_data = len(dataset_train)\n",
    "\n",
    "i = 0\n",
    "precision_matrices = {}\n",
    "for n, p in model.named_parameters():\n",
    "    precision_matrices[n] = p.clone().detach().fill_(0) \n",
    "for idx, data in enumerate(dataset_train):\n",
    "    with torch.cuda.device(0):\n",
    "        if torch.cuda.is_available():\n",
    "            features, regression, classification = model([data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0), data['annot'].cuda().unsqueeze(dim=0)])\n",
    "        else:\n",
    "            print('not have gpu')\n",
    "            break\n",
    "        classification = torch.norm(classification)\n",
    "        regression = torch.norm(regression)\n",
    "        ratio = float(classification / regression) \n",
    "        regression = regression * ratio\n",
    "        \n",
    "        output = classification + regression\n",
    "        output.backward()\n",
    "        \n",
    "        for n, p in model.named_parameters():                      \n",
    "            precision_matrices[n].data += p.grad.abs() / num_data ## difference with EWC      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T13:48:07.160382Z",
     "start_time": "2021-06-15T13:48:07.139842Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os\n",
    "class MAS(object):\n",
    "    def __init__(self, model: nn.Module, dataloader):\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "    def load_importance(path):\n",
    "        with open(os.path.join(path, \"MAS.pickle\")) as f:\n",
    "            self.precision_matrices = pickle.load(f)\n",
    "    def calculate_importance(self):\n",
    "        print('Computing MAS')\n",
    "        self.model.distill_feature = True\n",
    "        precision_matrices = {}\n",
    "        for n, p in self.params.items():\n",
    "            precision_matrices[n] = p.clone().detach().fill_(0)\n",
    "        self.model.train()\n",
    "        self.model.freeze_bn()\n",
    "        num_data = len(self.dataloader)\n",
    "        for idx, data in enumerate(self.dataloader):\n",
    "            with torch.cuda.device(0):\n",
    "                self.model.zero_grad()\n",
    "\n",
    "                features, regression, classification = self.model([data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0))\n",
    "                                                          \n",
    "                classification = torch.norm(classification)\n",
    "                regression = torch.norm(regression)\n",
    "                regression *= float(classification / regression) \n",
    "                output = classification + regression\n",
    "                output.backward()\n",
    "                                          \n",
    "                for n, p in self.model.named_parameters():                      \n",
    "                    precision_matrices[n].data += p.grad.abs() / num_data\n",
    "\n",
    "        self.model.distill_feature = False\n",
    "        self.precision_matrices = precision_matrices\n",
    "\n",
    "    def penalty(self, model: nn.Module):\n",
    "        loss = 0\n",
    "                                                                       \n",
    "        for n, p in model.named_parameters():\n",
    "            if \"classificationModel.output\" not in name:\n",
    "                _loss = self.precision_matrices[n] * (p - self.old_params[n]) ** 2\n",
    "                loss += _loss.sum()\n",
    "#             else:\n",
    "#                 _loss = self.precision_matrices[n] * (p[] - self.old_params[n]) ** 2                                                           \n",
    "#                 self.output.weight.data[i*20 + j,:,:,:] = old_output.weight.data[i*4 + part_idx,:,:,:]\n",
    "#                 self.output.bias.data[i*20 + j] = old_output.bias.data[i*4 + part_idx]\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:00:34.542074Z",
     "start_time": "2021-06-15T13:48:44.284350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MAS\n"
     ]
    }
   ],
   "source": [
    "mas = MAS(retinanet, dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:03:59.862983Z",
     "start_time": "2021-06-15T14:03:59.856792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method MAS.penalty of <__main__.MAS object at 0x7f510c767550>>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mas.penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:shiang]",
   "language": "python",
   "name": "conda-env-shiang-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
