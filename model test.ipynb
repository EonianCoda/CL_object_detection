{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T12:27:16.034166Z",
     "start_time": "2021-06-15T12:27:14.670050Z"
    },
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.14s)\n",
      "creating index...\n",
      "index created!\n",
      "{'id': [[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19], [6], [20], [14], [12], [13]], 'name': [['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person'], ['train'], ['sheep'], ['sofa'], ['pottedplant'], ['tvmonitor']]}\n",
      "dataloader class_num = 15\n",
      "readcheckpoint at Round1 Epoch50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from retinanet import model\n",
    "from retinanet import coco_eval\n",
    "from retinanet.dataloader import CocoDataset_inOrder,rehearsal_DataSet, collater, Resizer, AspectRatioBasedSampler, Augmenter, Normalizer\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import collections\n",
    "import torch\n",
    "root_path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/'\n",
    "method = 'w_distillation'\n",
    "data_split = '15+1'\n",
    "start_round = 1\n",
    "batch_size = 1\n",
    "\n",
    "checkpoint_epoch = 50\n",
    "\n",
    "def checkDir(path):\n",
    "    \"\"\"check whether directory exists or not.If not, then create it \n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "def get_checkpoint_path(method, now_round, epoch, data_split =\"None\"):\n",
    "    global root_path\n",
    "    # global data_split\n",
    "    \n",
    "    \n",
    "    checkDir(os.path.join(root_path, 'model', method, 'round{}'.format(now_round)))\n",
    "    checkDir(os.path.join(root_path, 'model', method, 'round{}'.format(now_round), data_split))\n",
    "    \n",
    "    path = os.path.join(root_path, 'model', method, 'round{}'.format(now_round), data_split,'voc_retinanet_{}_checkpoint.pt'.format(epoch))\n",
    "    return path\n",
    "\n",
    "\n",
    "def readCheckpoint(method, now_round, epoch, data_split, retinanet, optimizer = None, scheduler = None):\n",
    "    print('readcheckpoint at Round{} Epoch{}'.format(now_round, epoch))\n",
    "    prev_checkpoint = torch.load(get_checkpoint_path(method, now_round, epoch, data_split))\n",
    "    retinanet.load_state_dict(prev_checkpoint['model_state_dict'])\n",
    "    if optimizer != None:\n",
    "        optimizer.load_state_dict(prev_checkpoint['optimizer_state_dict'])\n",
    "    if scheduler != None:\n",
    "        scheduler.load_state_dict(prev_checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "\n",
    "\n",
    "# coco_path = '/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012'\n",
    "\n",
    "\n",
    "\n",
    "# dataset_train = CocoDataset_inOrder(coco_path, set_name='TrainVoc2012', dataset = 'voc',\n",
    "#                                     transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]),\n",
    "#                                    data_split=data_split, start_round=start_round)\n",
    "\n",
    "# # dataset_val = CocoDataset_inOrder(os.path.join(root_path, 'DataSet', 'VOC2012'), set_name=\"ValVoc2012\", dataset = 'voc', \n",
    "# #                 transform=transforms.Compose([Normalizer(), Resizer()]), \n",
    "# #                 start_round=1, data_split = \"20\")\n",
    "\n",
    "dataset_train = CocoDataset_inOrder(os.path.join(root_path, 'DataSet', 'VOC2012'), set_name='TrainVoc2012', dataset = 'voc',\n",
    "                                    transform=transforms.Compose([Normalizer(), Resizer()]),\n",
    "                                   data_split=data_split, start_round=start_round)\n",
    "retinanet = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "retinanet.cuda()\n",
    "\n",
    "# # sampler = AspectRatioBasedSampler(dataset_train, batch_size = batch_size, drop_last=False)\n",
    "# # dataloader_train = DataLoader(dataset_train, num_workers=2, collate_fn=collater, batch_sampler=sampler)\n",
    "\n",
    "\n",
    "\n",
    "# optimizer = optim.Adam(retinanet.parameters(), lr=1e-5)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "# loss_hist = collections.deque(maxlen=500)\n",
    "\n",
    "readCheckpoint(method, start_round, checkpoint_epoch,data_split, retinanet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改sample的data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T05:14:56.820120Z",
     "start_time": "2021-06-15T05:14:56.561461Z"
    }
   },
   "outputs": [],
   "source": [
    "rehearsal_dataset = rehearsal_DataSet('/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012', set_name='TrainVoc2012', dataset = 'voc',\n",
    "                        transform=transforms.Compose([Normalizer(), Resizer()]), \n",
    "                        data_split = \"15+1\",method = \"random\", per_num = 2)\n",
    "rehearsal_dataset.reset_by_round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T14:03:48.999930Z",
     "start_time": "2021-06-14T14:03:48.991342Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "catIds = rehearsal_dataset.classOrder['id'][0]\n",
    "\n",
    "names = rehearsal_dataset.cocoHelper.catIdToName(catIds)\n",
    "print(names)\n",
    "\n",
    "sample = defaultdict(list)\n",
    "i = 0\n",
    "\n",
    "for name in names:\n",
    "    for _ in range(2):\n",
    "        sample[name].append(rehearsal_dataset.image_ids[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T05:12:16.065268Z",
     "start_time": "2021-06-15T05:12:16.053054Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = {'person': [2008002080, 2008001302],\n",
    "         'car': [2010004059, 2010001043],\n",
    "         'bicycle': [2009004340, 2008004603],\n",
    "         'bus':     [2009004871, 2009004383], \n",
    "         'motorbike': [2010004848, 2011000233],\n",
    "         'aeroplane': [2009001541, 2008007629],\n",
    "         'boat':  [2008002850, 2008008616],\n",
    "         'chair': [2010004660, 2010002870],\n",
    "         'bottle': [2008006004, 2009005057],\n",
    "         'diningtable': [2011002818, 2010003078],\n",
    "         'bird': [2009001751, 2010003929],\n",
    "         'cat': [2009005037, 2009005177],\n",
    "         'cow': [2008008521, 2008008121],\n",
    "         'dog': [2010000484, 2008001479],\n",
    "         'horse': [2010004247, 2009001147]}\n",
    "\n",
    "samples = []\n",
    "for v in sample.values():\n",
    "    samples.extend(v)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T05:14:11.269262Z",
     "start_time": "2021-06-15T05:14:07.000957Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "per_num = 2\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4*per_num,50))\n",
    "gs = gridspec.GridSpec(len(samples) // per_num, per_num)\n",
    "i, j = 0, 0\n",
    "for imgId in samples:\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.subplot(gs[i,j])\n",
    "    plt.imshow(im)\n",
    "    j += 1\n",
    "    if j == per_num:\n",
    "        j = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T05:14:01.230915Z",
     "start_time": "2021-06-15T05:14:01.208621Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.gridspec as gridspec\n",
    "i = 0\n",
    "cat_name = 'motorbike'\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "future_class_id = []\n",
    "for i in range(1, len(rehearsal_dataset.classOrder['id'])):\n",
    "    future_class_id.extend(rehearsal_dataset.classOrder['id'][i])\n",
    "\n",
    "future_imgIds = set(rehearsal_dataset.cocoHelper.getImgIdFromCats(future_class_id))\n",
    "\n",
    "imgIds = rehearsal_dataset.cocoHelper.getImgIdFromCats(catIds=rehearsal_dataset.cocoHelper.catNameToId(cat_name))\n",
    "\n",
    "imgIds = list(set(imgIds) - set(future_imgIds)) \n",
    "\n",
    "random.shuffle(imgIds)\n",
    "for imgId in imgIds:\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.figure()\n",
    "    plt.title(imgId)\n",
    "    plt.imshow(im)\n",
    "    i += 1\n",
    "    if i == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T05:15:07.267439Z",
     "start_time": "2021-06-15T05:15:03.042673Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "catIds = rehearsal_dataset.classOrder['id'][0]\n",
    "names = rehearsal_dataset.cocoHelper.catIdToName(catIds)\n",
    "print(names)\n",
    "per_num = 2\n",
    "\n",
    "plt.figure(figsize=(4*per_num,50))\n",
    "gs = gridspec.GridSpec(len(rehearsal_dataset.image_ids) // per_num, per_num)\n",
    "i, j = 0, 0\n",
    "for imgId in rehearsal_dataset.image_ids:\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.subplot(gs[i,j])\n",
    "    plt.imshow(im)\n",
    "    j += 1\n",
    "    if j == per_num:\n",
    "        j = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-14T12:47:27.196444Z",
     "start_time": "2021-06-14T12:47:22.813350Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "names = [name for name in rehearsal_dataset.classOrder['id'][:15]]\n",
    "print(names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,50))\n",
    "gs = gridspec.GridSpec(len(rehearsal_dataset.image_ids) // 2, 2)\n",
    "i, j = 0, 0\n",
    "for imgId in rehearsal_dataset.image_ids:\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.subplot(gs[i,j])\n",
    "    plt.imshow(im)\n",
    "    j += 1\n",
    "    if j == 2:\n",
    "        j = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T16:20:34.252094Z",
     "start_time": "2021-06-06T16:20:27.947444Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "names = [name for name in rehearsal_dataset.classOrder['name'][:15]]\n",
    "print(names)\n",
    "for imgId in rehearsal_dataset.image_ids:\n",
    "    print(imgId)\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.figure()\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:34:06.117883Z",
     "start_time": "2021-06-06T15:33:59.922793Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "img_path = \"/home/deeplab307/Documents/Anaconda/Shiang/CL/DataSet/VOC2012/images\"\n",
    "\n",
    "\n",
    "names = [name for name in rehearsal_dataset.classOrder['name'][:15]]\n",
    "print(names)\n",
    "for imgId in rehearsal_dataset.image_ids:\n",
    "\n",
    "    im = cv2.imread(os.path.join(img_path, str(imgId)[:4] + '_' + str(imgId)[4:] +'.jpg'))\n",
    "    plt.figure()\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 檢查模型間參數的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:08:15.286291Z",
     "start_time": "2021-06-02T09:08:09.989451Z"
    }
   },
   "outputs": [],
   "source": [
    "retinanet = model.resnet50(num_classes=16, pretrained=True)\n",
    "retinanet_upper = model.resnet50(num_classes=16, pretrained=True)\n",
    "retinanet15 = model.resnet50(num_classes=15, pretrained=True)\n",
    "readCheckpoint(\"w_distillation\", now_round = 2, epoch = 50, data_split=\"15+1\",retinanet=retinanet)\n",
    "readCheckpoint(\"special_try\", now_round = 1, epoch = 50, data_split=\"custom\",retinanet=retinanet_upper)\n",
    "readCheckpoint(\"w_distillation\", now_round = 1, epoch = 50, data_split=\"15+1\",retinanet=retinanet15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:08:15.400303Z",
     "start_time": "2021-06-02T09:08:15.396441Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_names(model):\n",
    "    names = []\n",
    "    for name,parameters in model.named_parameters():\n",
    "        names.append(name)\n",
    "    return names\n",
    "names = get_names(retinanet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:11:59.977551Z",
     "start_time": "2021-06-02T09:11:59.158315Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "MSE = nn.MSELoss()\n",
    "L1 = nn.L1Loss()\n",
    "\n",
    "diffs_for_15 = defaultdict(float)\n",
    "diffs = defaultdict(float)\n",
    "for name in names:\n",
    "    if \"classificationModel.output\" not in name:\n",
    "        diff = MSE(retinanet_upper.state_dict()[name], retinanet15.state_dict()[name])\n",
    "        diffs_for_15[name] = float(diff)\n",
    "    diff = MSE(retinanet.state_dict()[name], retinanet_upper.state_dict()[name])\n",
    "    diffs[name] = float(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:28:38.531105Z",
     "start_time": "2021-06-02T09:28:38.522730Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_rank(diffs):\n",
    "    diffs_keys = [key for key in diffs.keys()]\n",
    "    diffs_values = list(diffs.values())\n",
    "    ascending = sorted(range(len(diffs)), key=lambda k: diffs_values[k])\n",
    "    \n",
    "    num = 100\n",
    "    \n",
    "    for idx in ascending[len(ascending) - num:]:\n",
    "        print(diffs_keys[idx], diffs_values[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算所有data loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:43:56.995758Z",
     "start_time": "2021-05-27T13:35:11.543629Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "retinanet.train()\n",
    "retinanet.freeze_bn()\n",
    "\n",
    "dataset = dataset_train\n",
    "\n",
    "fail_id = []\n",
    "losses = collections.defaultdict(list)\n",
    "\n",
    "for idx, data in enumerate(dataset):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.device(0):\n",
    "            if torch.cuda.is_available():\n",
    "                classification_loss, regression_loss = retinanet([data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0), data['annot'].cuda().unsqueeze(dim=0)])\n",
    "            else:\n",
    "                print('not have gpu')\n",
    "                break\n",
    "\n",
    "            classification_loss = classification_loss.mean()\n",
    "            regression_loss = regression_loss.mean()\n",
    "\n",
    "            img_id = dataset.image_ids[idx]\n",
    "\n",
    "\n",
    "            classification_loss = float(classification_loss)\n",
    "            regression_loss = float(regression_loss)\n",
    "            loss = classification_loss + regression_loss\n",
    "\n",
    "            losses[img_id] = [classification_loss, regression_loss, loss]\n",
    "\n",
    "            #optimizer.step()\n",
    "            loss_hist.append(float(loss))\n",
    "\n",
    "            #epoch_loss.append(float(loss))\n",
    "            end = time.time()\n",
    "\n",
    "            print('Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f} | Spend Time:{:1.2f}s'.format(\n",
    "                                              '50', \n",
    "                                              idx, \n",
    "                                              float(classification_loss), \n",
    "                                              float(regression_loss), \n",
    "                                              np.mean(loss_hist),\n",
    "                                              end - start))\n",
    "            del classification_loss\n",
    "            del regression_loss\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        fail_id.append(idx)\n",
    "        continue\n",
    "\n",
    "print('fail_id:',fail_id)\n",
    "\n",
    "\n",
    "with open(os.path.join(\"/\".join(get_checkpoint_path(method, 1, 50).split('/')[:-1]), 'losses.pickle'), 'wb') as f:\n",
    "    pickle.dump(losses, f)\n",
    "#print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:13:50.683846Z",
     "start_time": "2021-06-06T15:13:50.595229Z"
    }
   },
   "outputs": [],
   "source": [
    "img = dataset_train.load_image(74)\n",
    "ann = dataset_train.load_annotations(74)\n",
    "data = {'img': img, 'annot': ann}\n",
    "data = dataset_train.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:16:08.944527Z",
     "start_time": "2021-06-06T15:16:08.937293Z"
    }
   },
   "outputs": [],
   "source": [
    "data['annot'].cuda().unsque`eze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:12:23.923486Z",
     "start_time": "2021-06-06T15:12:23.916190Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train.cocoHelper.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:13:55.381660Z",
     "start_time": "2021-06-06T15:13:55.315557Z"
    }
   },
   "outputs": [],
   "source": [
    "retinanet.each_cat_loss = True\n",
    "classification_loss, _ = retinanet([data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0), data['annot'].cuda().unsqueeze(dim=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T15:11:29.945048Z",
     "start_time": "2021-06-06T15:11:29.936988Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分別為每個類別計算loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T14:46:42.703754Z",
     "start_time": "2021-06-06T14:37:59.732942Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "retinanet.train()\n",
    "retinanet.freeze_bn()\n",
    "\n",
    "dataset = dataset_train\n",
    "\n",
    "fail_id = []\n",
    "losses = [collections.defaultdict() for _ in dataset.seen_class_id]\n",
    "\n",
    "retinanet.each_cat_loss = True\n",
    "for idx, data in enumerate(dataset):\n",
    "\n",
    "    try:\n",
    "        with torch.cuda.device(0):\n",
    "            if torch.cuda.is_available():\n",
    "                classification_loss, _ = retinanet([data['img'].permute(2, 0, 1).cuda().float().unsqueeze(dim=0), data['annot'].cuda().unsqueeze(dim=0)])\n",
    "            else:\n",
    "                print('not have gpu')\n",
    "                break\n",
    "\n",
    "\n",
    "            img_id = dataset.image_ids[idx]\n",
    "\n",
    "            for key in classification_loss.keys():\n",
    "                losses[key][img_id] = float(np.mean(classification_loss[key]))\n",
    "\n",
    "            print(idx)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        fail_id.append(idx)\n",
    "        continue\n",
    "\n",
    "print('fail_id:',fail_id)\n",
    "\n",
    "\n",
    "with open(os.path.join(\"/\".join(get_checkpoint_path(method, 1, 50,data_split).split('/')[:-1]), 'losses_each_cat_new.pickle'), 'wb') as f:\n",
    "    pickle.dump(losses, f)\n",
    "#print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T14:36:16.411626Z",
     "start_time": "2021-06-06T14:36:16.405118Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_loss.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T05:34:58.264517Z",
     "start_time": "2021-06-06T05:34:58.209957Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(\"/\".join(get_checkpoint_path(method, 1, 50,data_split).split('/')[:-1]), 'losses_each_cat.pickle'), 'rb') as f:\n",
    "    losses = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-06T05:35:24.814800Z",
     "start_time": "2021-06-06T05:35:24.807388Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in losses:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:55:41.434110Z",
     "start_time": "2021-05-27T13:55:41.348495Z"
    }
   },
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:48:23.556669Z",
     "start_time": "2021-05-27T13:48:23.548848Z"
    }
   },
   "outputs": [],
   "source": [
    "os.path.join(\"/\".join(get_checkpoint_path(method, 1, 50).split('/')[:-1]), 'losses.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:58:00.745982Z",
     "start_time": "2021-05-27T13:58:00.740224Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = [v[2] for v in losses.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T13:58:20.940278Z",
     "start_time": "2021-05-27T13:58:20.917729Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:10:11.360151Z",
     "start_time": "2021-04-06T18:10:11.054507Z"
    }
   },
   "outputs": [],
   "source": [
    "method = 'w_distillation'\n",
    "\n",
    "for i in range(50,51,10):\n",
    "    print(np.mean(readCheckpoint(method, 1, i)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:09:05.086275Z",
     "start_time": "2021-04-06T18:09:04.282162Z"
    }
   },
   "outputs": [],
   "source": [
    "method = 'incremental'\n",
    "\n",
    "for i in range(10,31,10):\n",
    "    print(np.mean(readCheckpoint(method, 1, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:05:13.442587Z",
     "start_time": "2021-04-06T18:05:12.170534Z"
    }
   },
   "outputs": [],
   "source": [
    "method = 'incremental'\n",
    "\n",
    "for i in range(10,51,10):\n",
    "    print(np.mean(readCheckpoint(method, 0, i)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(readCheckpoint(method, 0, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T04:32:59.345393Z",
     "start_time": "2021-04-06T04:32:59.339106Z"
    }
   },
   "outputs": [],
   "source": [
    "parts = []\n",
    "\n",
    "for i in range(0,4):\n",
    "    parts.append(retinanet.classificationModel.output.weight.data[i*9: i*9 + 9,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T04:33:01.611318Z",
     "start_time": "2021-04-06T04:33:01.601089Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "output = nn.Conv2d(256, 9 * 20, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T04:36:24.690145Z",
     "start_time": "2021-04-06T04:36:24.679573Z"
    }
   },
   "outputs": [],
   "source": [
    "output.weight.data[0:9,:,:,:] = parts[3]\n",
    "#vehicle(7)\n",
    "for i in range(0,7):\n",
    "    output.weight.data[9 + i*9:9 + i*9 + 9,:,:,:] = parts[0]\n",
    "#furniture(6)\n",
    "for i in range(0,6):\n",
    "    output.weight.data[72 + i*9:72 + i*9 + 9,:,:,:] = parts[1]\n",
    "#animals(6)\n",
    "for i in range(0,6):\n",
    "    output.weight.data[126 + i*9:126 + i*9 + 9,:,:,:] = parts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T04:36:53.559211Z",
     "start_time": "2021-04-06T04:36:53.550539Z"
    }
   },
   "outputs": [],
   "source": [
    "(output.weight.data[72:81,:,:,:] == output.weight.data[81:90,:,:,:]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:29:31.511361Z",
     "start_time": "2021-03-16T17:29:31.372639Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "prev_model = copy.deepcopy(retinanet)\n",
    "retinanet.increase_class(1)\n",
    "\n",
    "retinanet.cuda()\n",
    "prev_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:29:38.239997Z",
     "start_time": "2021-03-16T17:29:38.234111Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "test = torch.ones(2,256,30,30).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:29:39.297163Z",
     "start_time": "2021-03-16T17:29:39.286858Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_out = prev_model.classificationModel.output_act(prev_model.classificationModel.output(test))\n",
    "cur_out = retinanet.classificationModel.output_act(retinanet.classificationModel.output(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-16T17:29:52.746312Z",
     "start_time": "2021-03-16T17:29:52.734269Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def change_shape1(out, num_classes):\n",
    "    out1 = out.permute(0, 2, 3, 1)\n",
    "    batch_size, width, height, channels = out1.shape\n",
    "    out1 = out1.view(batch_size, width, height, 9, num_classes)\n",
    "    \n",
    "    return out1.contiguous().view(2, -1, num_classes)\n",
    "def change_shape2(out, num_classes):\n",
    "    out1 = out.permute(0, 2, 3, 1)\n",
    "    batch_size, width, height, channels = out1.shape\n",
    "    out1 = out1.view(batch_size, width, height,num_classes, 9)\n",
    "    \n",
    "    out1 = out1.permute(0, 1, 2, 4, 3)\n",
    "    \n",
    "    return out1.contiguous().view(2, -1, num_classes)\n",
    "prev_out_new1 = change_shape1(prev_out, 19)\n",
    "cur_out_new1 = change_shape1(cur_out, 20)\n",
    "\n",
    "# prev_out_new2 = change_shape2(prev_out, 19)\n",
    "# cur_out_new2 = change_shape2(cur_out, 20)\n",
    "# (prev_out == cur_out[:,:171,:,:]).any()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:shiang]",
   "language": "python",
   "name": "conda-env-shiang-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
